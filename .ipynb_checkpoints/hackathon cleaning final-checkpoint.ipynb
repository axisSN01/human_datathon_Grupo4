{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "df = pd.read_csv('full.csv', low_memory=False)\n",
    "\n",
    "def normalize_column(df, column_name):\n",
    "    df[column_name] = df[column_name].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
    "    return df[column_name]\n",
    "\n",
    "def inspect_column(df, col):\n",
    "    print(f'Column: {col}')\n",
    "    print(f'Unique values: {len(df[col].unique())}')\n",
    "    print(f'Null values: {df[col].isna().sum()}')\n",
    "    display(df[[col, 'identificador']].groupby(by=col, as_index=False).count().sort_values(by='identificador', ascending=False))\n",
    "    \n",
    "train = df\n",
    "test = pd.read_csv('test.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in test.columns:\n",
    "#     print(f'column {col}, {test.isna().mean()} missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['target'] = train['Salario mensual (en tu moneda local)']/train['Valor dólar informal semestral']\n",
    "\n",
    "target = 'target'\n",
    "onehot_features = []\n",
    "mean_features = ['Dónde estás trabajando',\n",
    "                'Tipo de contrato',\n",
    "                'Actividad principal',\n",
    "                 \n",
    "                         ]\n",
    "delete_columns = ['Trabajo de',\n",
    "                    'Me identifico',\n",
    "                    'Lenguajes de programación o tecnologías.',\n",
    "                    'Automation o funcional?',\n",
    "                    'QA / Testing',\n",
    "                    'Bases de datos',\n",
    "                    'Cuánto cobrás por guardia',\n",
    "                    '¿Porcentaje, bruto o neto?',\n",
    "                    'Plataformas',\n",
    "                    'A qué está atado el bono',\n",
    "                    'Valor dólar informal semestral',\n",
    "                    'Frameworks, herramientas y librerías',\n",
    "                    'Universidad', \n",
    "                    'Años en la empresa actual',\n",
    "                    '¿Programás como hobbie?',\n",
    "                    'Lenguajes de programación', \n",
    "                    'IDEs',\n",
    "                    '¿Qué SO usás en tu laptop/PC para trabajar?',\n",
    "                    'Orientación sexual',\n",
    "                    '¿Sentís que esto te dificultó el conseguir trabajo?',\n",
    "                    'Frameworks, herramientas y librerías',\n",
    "                    'Nivel de estudios alcanzado',\n",
    "                    '¿Sufriste o presenciaste situaciones de violencia laboral?',\n",
    "                    '¿Tenés algún tipo de discapacidad?',\n",
    "                    'Trabajo para una empresa que no tiene oficina en mi ciudad',\n",
    "                    '¿Cómo venís llevando la pandemia?',\n",
    "                    'Sufriste o presenciaste situaciones de violencia y/o acoso por motivo de',\n",
    "                    '¿Considerás que en tu empresa/organización hay una marcada tendencia a escuchar más a los hombres?',\n",
    "                    '¿Sentís que podés ser vos en tu trabajo?',\n",
    "                    '¿Considerás que tenés oportunidades de crecimiento siendo quien sos dentro de tu organización?',\n",
    "                    '¿Sentís que alguna vez los prejuicios culturales/sociales sobre tu orientación, género, etnia o discapacidad pudieron obstaculizar el que consigas un trabajo?',\n",
    "                    'En el último año, en tu trabajo ¿recibiste o escuchaste comentarios que considerás inapropiados, subidos de tono y/o discriminatorios?',\n",
    "                    '¿Cuántas veces a la semana vas a trabajar a la oficina?',\n",
    "                    '¿Cómo venís llevando la cuarentena?',\n",
    "                    '¿Tenés hijos/as menores de edad?',\n",
    "                    '¿Qué tipo de cuarentena hiciste / estás haciendo?',\n",
    "                    '¿Cambió tu situación laboral a raíz de la pandemia?',\n",
    "                    '¿Qué tanto sentís que te está apoyando tu empresa/organización en esta situación?',\n",
    "                    '¿Cómo se vio afectada tu empresa/organización?',\n",
    "                  'Pagos en dólares',\n",
    "                 ]\n",
    "\n",
    "if onehot_features:\n",
    "    onehotter = OneHotEncoder(handle_unknown='infrequent_if_exist', min_frequency=0.001, drop='if_binary')\n",
    "    onehotter.fit(train[onehot_features])\n",
    "\n",
    "if mean_features:\n",
    "    mean_encoder = {'unk': train[target].mean()}\n",
    "    for col in mean_features:\n",
    "        mean_encoder[col] = train.groupby([col])[target].mean().to_dict()\n",
    "\n",
    "def clean_pipeline(df, test=False):\n",
    "    \n",
    "    # gender\n",
    "    df['Me identifico'] = normalize_column(df, 'Me identifico')\n",
    "    male_regex = 'varon|hombre|macho|mascul'\n",
    "    female_regex = 'mujer|femen'\n",
    "    df['gender_male'] = np.where(df['Me identifico'].str.contains(male_regex, case=False), 1, 0)\n",
    "    df['gender_female'] = np.where(df['Me identifico'].str.contains(female_regex, case=False), 1, 0)\n",
    "    df['gender_unk'] = np.where((df['gender_male']==0) & (df['gender_female']==0), 1, 0)\n",
    "    \n",
    "    # geography\n",
    "    north_provinces = {'Jujuy', 'Chaco', 'Catamarca', 'Corrientes', 'Santiago del Estero', 'Tucumán', 'Misiones', 'Formosa', 'Salta'}\n",
    "    x1 = {key: 'North' for key in north_provinces}\n",
    "    south_provinces = {'Neuquén', 'Río Negro', 'Chubut', 'Tierra del Fuego', 'Santa Cruz'}\n",
    "    x2 = {key: 'South' for key in south_provinces}\n",
    "    center_provinces = {'La Rioja', 'San Juan', 'Mendoza', 'La Pampa', 'Entre Ríos', 'Santa Fe', 'San Luis'}\n",
    "    x3 = {key: 'Center' for key in center_provinces}\n",
    "    province_dict= {'Provincia de Buenos Aires': 'PBA', 'GBA':'PBA', 'Ciudad Autónoma de Buenos Aires': 'CABA', 'Córdoba': 'Cordoba'}\n",
    "    province_dict.update(x1)\n",
    "    province_dict.update(x2)\n",
    "    province_dict.update(x3)\n",
    "    df['Dónde estás trabajando'] = df['Dónde estás trabajando'].map(province_dict)\n",
    "    df['Dónde estás trabajando'] = df['Dónde estás trabajando'].fillna('CABA')\n",
    "    \n",
    "    # experiencia\n",
    "    if df['Años de experiencia'].dtype != 'float64':\n",
    "        df['Años de experiencia'] = df['Años de experiencia'].str.split('.').str[0]\n",
    "        df['Años de experiencia'] = pd.to_numeric(df['Años de experiencia'].str.split(',').str[0].str.replace('\\D+', ''))\n",
    "    df['Años de experiencia'] = pd.cut(df['Años de experiencia'], [-1, 2, 5, 9, 100000], labels=False , retbins=True, right=True)[0]\n",
    "    df['Años de experiencia'] = df['Años de experiencia'].fillna(0) #the only value is Less than a year that corresponds to the bin 0\n",
    "    \n",
    "    if df['Años en el puesto actual'].dtype != 'float64':\n",
    "        df['Años en el puesto actual'] = df['Años en el puesto actual'].str.split('.').str[0]\n",
    "        df['Años en el puesto actual'] = pd.to_numeric(df['Años en el puesto actual'].str.split(',').str[0].str.replace('\\D+', ''))\n",
    "    df['Años en el puesto actual'] = pd.cut(df['Años en el puesto actual'], [-1, 1, 3, 5, 100000], labels=False , retbins=True, right=True)[0]\n",
    "    df['Años en el puesto actual'] = df['Años en el puesto actual'].fillna(0) #the only value is Less than a year that corresponds to the bin 0\n",
    "    \n",
    "    # job post\n",
    "    df['Trabajo de'] = normalize_column(df, 'Trabajo de')\n",
    "    admin_regex = 'admin'\n",
    "    manager_regex = 'manager|gesti|geren'\n",
    "    agile_regex = 'agile'\n",
    "    analyst_regex = 'anal'\n",
    "    data_regex = 'data|ML|machine|DBA'\n",
    "    engineer_regex = 'ingen|engine'\n",
    "    support_regex = 'suppor|apoy|sopor|help'\n",
    "    qa_regex = 'qa|test'\n",
    "    dev_regex = 'dev|desarr'\n",
    "    designer_regex = 'disen|desig'\n",
    "    lead_regex = 'lead|CTO|C-level|C-suite'\n",
    "    df['job_admin'] = np.where(df['Trabajo de'].str.contains(admin_regex, case=False), 1, 0)\n",
    "    df['job_manager'] = np.where(df['Trabajo de'].str.contains(manager_regex, case=False), 1, 0)\n",
    "    df['job_agile'] = np.where(df['Trabajo de'].str.contains(agile_regex, case=False), 1, 0)\n",
    "    df['job_analyst'] = np.where(df['Trabajo de'].str.contains(analyst_regex, case=False), 1, 0)\n",
    "    df['job_data'] = np.where(df['Trabajo de'].str.contains(data_regex, case=False), 1, 0)\n",
    "    df['job_engineer'] = np.where(df['Trabajo de'].str.contains(engineer_regex, case=False), 1, 0)\n",
    "    df['job_support'] = np.where(df['Trabajo de'].str.contains(support_regex, case=False), 1, 0)\n",
    "    df['job_qa'] = np.where(df['Trabajo de'].str.contains(qa_regex, case=False), 1, 0)\n",
    "    df['job_dev'] = np.where(df['Trabajo de'].str.contains(dev_regex, case=False), 1, 0)\n",
    "    df['job_designer'] = np.where(df['Trabajo de'].str.contains(designer_regex, case=False), 1, 0)\n",
    "    # job_lead can be inferred from number of subordinates better\n",
    "    # df['job_lead'] = np.where(df['Trabajo de'].str.contains(lead_regex, case=False), 1, 0)\n",
    "    \n",
    "    # age\n",
    "    if df['Años de experiencia'].dtype != 'int64':\n",
    "        df['Tengo'] = df['Tengo'].str.split('-').str[0]\n",
    "        df['Tengo'] = pd.to_numeric(df['Tengo'].str.replace('\\D+', ''))\n",
    "    df['Tengo'] = df['Tengo'].fillna(df['Tengo'].mean())\n",
    "    df['Tengo'] = pd.cut(df['Tengo'], [-1, 25, 30, 35, 45, 100000], labels=False , retbins=True, right=True)[0]\n",
    "\n",
    "    # platforms\n",
    "    df['Plataformas'] = df['Plataformas'].fillna('Ninguna de las anteriores')\n",
    "    df['Plataformas'] = normalize_column(df, 'Plataformas')\n",
    "    cloud_regex = 'amazon|aws|cloud|azure|ocean|gcp'\n",
    "    wind_regex = 'wind|micros'\n",
    "    db_regex = 'sql|terad|databr|fireba|query|mongo'\n",
    "    bi_regex = 'tableau|powerbi|looker'\n",
    "    jira_regex = 'jira|atlas'\n",
    "    linux_regex = 'linux|debian|redhat|ubuntu|centos'\n",
    "    df['platform_cloud'] = np.where(df['Plataformas'].str.contains(cloud_regex, case=False), 1, 0)\n",
    "    df['platform_wind'] = np.where(df['Plataformas'].str.contains(wind_regex, case=False), 1, 0)\n",
    "    df['platform_db'] = np.where(df['Plataformas'].str.contains(db_regex, case=False), 1, 0)\n",
    "    df['platform_bi'] = np.where(df['Plataformas'].str.contains(bi_regex, case=False), 1, 0)\n",
    "    df['platform_jira'] = np.where(df['Plataformas'].str.contains(jira_regex, case=False), 1, 0)\n",
    "    df['platform_linux'] = np.where(df['Plataformas'].str.contains(linux_regex, case=False), 1, 0)\n",
    "    \n",
    "    # test_framework\n",
    "    df['QA / Testing'] = df['QA / Testing'].fillna('Ninguna de las anteriores')\n",
    "    df['QA / Testing'] = normalize_column(df, 'QA / Testing')\n",
    "    notest_regex = 'none|ning|no/s|ni/s|no$'\n",
    "    df['test_notests'] = np.where(df['QA / Testing'].str.contains(notest_regex, case=False), 1, 0)\n",
    "    \n",
    "    # languages\n",
    "    df['Lenguajes de programación o tecnologías.'] = normalize_column(df, 'Lenguajes de programación o tecnologías.')\n",
    "    df['Lenguajes de programación o tecnologías.'] = df['Lenguajes de programación o tecnologías.'].fillna('Ninguno de los anteriores')\n",
    "    c_regex = 'assembler|C\\+\\+|C\\#|C$|rust|smalltalk'\n",
    "    stat_regex = 'SAS|julia|SSIS|R$|matlab'\n",
    "    js_regex = 'javascript|ux|html|angular|react|typescript'\n",
    "    python_regex = 'python'\n",
    "    java_regex = 'java$|clojure|scala|kotlin|groovy'\n",
    "    bash_regex = 'bash|shell|yaml'\n",
    "    excel_regex = 'excel|vb|basic'\n",
    "    df['lang_c'] = np.where(df['Lenguajes de programación o tecnologías.'].str.contains(c_regex, case=False), 1, 0)\n",
    "    df['lang_stat'] = np.where(df['Lenguajes de programación o tecnologías.'].str.contains(stat_regex, case=False), 1, 0)\n",
    "    df['lang_js'] = np.where(df['Lenguajes de programación o tecnologías.'].str.contains(js_regex, case=False), 1, 0)\n",
    "    df['lang_python'] = np.where(df['Lenguajes de programación o tecnologías.'].str.contains(python_regex, case=False), 1, 0)\n",
    "    df['lang_java'] = np.where(df['Lenguajes de programación o tecnologías.'].str.contains(java_regex, case=False), 1, 0)\n",
    "    df['lang_bash'] = np.where(df['Lenguajes de programación o tecnologías.'].str.contains(bash_regex, case=False), 1, 0)\n",
    "    df['lang_excel'] = np.where(df['Lenguajes de programación o tecnologías.'].str.contains(excel_regex, case=False), 1, 0)\n",
    "    \n",
    "    # database\n",
    "    df['Bases de datos'] = df['Bases de datos'].fillna('Ninguna de las anteriores')\n",
    "    df['Bases de datos'] = normalize_column(df, 'Bases de datos')\n",
    "    sql_regex = 'MariaDB|oracle|postgre|sql|SOQL'\n",
    "    nouse_regex = 'none|ning|no/s|ni/s'\n",
    "    df['db_sql'] = np.where(df['Bases de datos'].str.contains(sql_regex, case=False), 1, 0)\n",
    "    df['db_nouse'] = np.where(df['Bases de datos'].str.contains(nouse_regex, case=False), 1, 0)\n",
    "    \n",
    "    # bono\n",
    "    bono_mapping = {'No': 0, 'Menos de un sueldo': 1, 'Un sueldo': 2, 'De uno a tres sueldos': 3, '3+ sueldos': 4}\n",
    "    df['Recibís algún tipo de bono'] = df['Recibís algún tipo de bono'].map(bono_mapping)\n",
    "    df['Recibís algún tipo de bono'] = df['Recibís algún tipo de bono'].fillna(0)\n",
    "    \n",
    "    # guardias\n",
    "    df['¿Tenés guardias?'] = df['¿Tenés guardias?'].fillna('No')\n",
    "    df['¿Tenés guardias?'] = normalize_column(df, '¿Tenés guardias?')\n",
    "    yes_regex = 'si'\n",
    "    df['¿Tenés guardias?'] = np.where(df['¿Tenés guardias?'].str.contains(yes_regex, case=False), 1, 0)\n",
    "    \n",
    "    # gente a cargo\n",
    "    df['¿Gente a cargo?'] = pd.cut(df['¿Gente a cargo?'], [-1, 0, 5, 20, 100000], labels=False , retbins=True, right=True)[0]\n",
    "\n",
    "\n",
    "    # platforms\n",
    "    df['Frameworks, herramientas y librerías'] = df['Frameworks, herramientas y librerías'].fillna('Ninguno de los anteriores')\n",
    "    df['Frameworks, herramientas y librerías'] = normalize_column(df, 'Frameworks, herramientas y librerías')\n",
    "    backend_regex = 'Spring|\\.net|django|node|nest|express|fast|flask|graph|hibern|laravel|rail|sqlalc|goland|go land|php'\n",
    "    frontend_regex = 'react|vue|angular|js|jquery|tailwind'\n",
    "    data_regex = 'spark|hadoop|sklea|pandas|numpy|spss|torch|tensor|keras|opencv|airflow'\n",
    "    df['framework_backend'] = np.where(df['Frameworks, herramientas y librerías'].str.contains(backend_regex, case=False), 1, 0)\n",
    "    df['framework_frontend'] = np.where(df['Frameworks, herramientas y librerías'].str.contains(frontend_regex, case=False), 1, 0)\n",
    "    df['framework_data'] = np.where(df['Frameworks, herramientas y librerías'].str.contains(data_regex, case=False), 1, 0)\n",
    "    \n",
    "    \n",
    "    # company size \n",
    "    # 0 - 51 - 200 - 2000 - 10000 - \n",
    "    compsize_mapping = {'11-50': 0, \n",
    "                    '2-10': 0,\n",
    "                    '1 (solamente yo)': 0,\n",
    "                    '1-10': 0, \n",
    "                    '51-100': 1, \n",
    "                    '101-200': 1,\n",
    "                    '201-500': 2, \n",
    "                    '501-1000': 2, \n",
    "                    '1001-2000': 2,\n",
    "                    '1001+': 2,\n",
    "                    '2001-5000': 3,\n",
    "                    '5001-10000': 3, \n",
    "                    '10001+': 3}\n",
    "    df['Cantidad de personas en tu organización'] = df['Cantidad de personas en tu organización'].map(compsize_mapping)\n",
    "\n",
    "\n",
    "\n",
    "    # education\n",
    "    education_mapping = {\n",
    "                    'Primario': 0,\n",
    "                    'Secundario': 0, \n",
    "                    'Terciario': 1, \n",
    "                    'Universitario': 2, \n",
    "                    'Posgrado': 3, \n",
    "                    'Doctorado': 3, \n",
    "                    'Posdoctorado' : 3}\n",
    "    df['Nivel de estudios alcanzado'] = df['Nivel de estudios alcanzado'].map(education_mapping)\n",
    "    df['education_isnan'] = np.where(df['Nivel de estudios alcanzado'].isna(), 1, 0)\n",
    "\n",
    "\n",
    "    #estado\n",
    "    education_state_mapping = {'En curso': 0, \n",
    "                    'Incompleto': 0, \n",
    "                    'Completado' : 1}\n",
    "    df['Estado'] = df['Estado'].map(education_state_mapping)\n",
    "\n",
    "\n",
    "    #carrera\n",
    "    df['Carrera'] = df['Carrera'].fillna('placeholder')\n",
    "    df['Carrera'] = normalize_column(df, 'Carrera')\n",
    "    tech_regex = 'cien|ing|anal|infor'\n",
    "    df['Carrera'] = np.where(df['Carrera'].str.contains(tech_regex, case=False), 1, 0)\n",
    "\n",
    "\n",
    "    #cursos especializacion\n",
    "    df['Realizaste cursos de especialización'] = df['Realizaste cursos de especialización'].fillna('placeholder')\n",
    "    df['Realizaste cursos de especialización'] = normalize_column(df, 'Realizaste cursos de especialización')\n",
    "    df['Realizaste cursos de especialización'] = np.where(df['Realizaste cursos de especialización'].str.contains('Si', case=False), 1, 0)\n",
    "\n",
    "    #contribucion open source\n",
    "    df['¿Contribuís a proyectos open source?'] = df['¿Contribuís a proyectos open source?'].fillna('placeholder')\n",
    "    df['¿Contribuís a proyectos open source?'] = normalize_column(df, '¿Contribuís a proyectos open source?')\n",
    "    df['¿Contribuís a proyectos open source?'] = np.where(df['¿Contribuís a proyectos open source?'].str.contains('Si', case=False), 1, 0)\n",
    "\n",
    "    #Discpacidad\n",
    "    regex_disc = r'\\bno\\b/gm'\n",
    "    df['¿Tenés algún tipo de discapacidad?'] = df['¿Tenés algún tipo de discapacidad?'].fillna('placeholder')\n",
    "    df['¿Tenés algún tipo de discapacidad?'] = normalize_column(df, '¿Tenés algún tipo de discapacidad?')\n",
    "    df['¿Tenés algún tipo de discapacidad?'] = np.where(df['¿Tenés algún tipo de discapacidad?'].str.contains(regex_disc, case=False),1,0)\n",
    "    \n",
    "    #actividad\n",
    "    df['actividad_isnan'] = np.where(df['Actividad principal'].isna(), 1, 0)\n",
    "    #recommendation\n",
    "    df['recommendation_isnan'] = np.where(df['¿La recomendás como un buen lugar para trabajar?'].isna(), 1, 0)\n",
    "    #diversidad\n",
    "    df['deiversity_isnan'] = np.where(df['¿Cómo calificás las políticas de diversidad e inclusión?'].isna(), 1, 0)\n",
    "    #dollar pay\n",
    "    df['dollar_isnan'] = np.where(df['Pagos en dólares'].isna(), 1, 0)\n",
    "    #pandemia\n",
    "    df['pandemia_isnan'] = np.where(df['¿Qué tanto sentís que te está apoyando tu empresa/organización en esta situación?'].isna(), 1, 0)\n",
    "    \n",
    "    \n",
    "    # ONEHOT ENCODING\n",
    "    if onehot_features:\n",
    "        onehot_data = onehotter.transform(df[onehot_features]).toarray()\n",
    "        onehot_columns = onehotter.get_feature_names_out([x for x in onehot_features])\n",
    "        onehot_data = pd.DataFrame(onehot_data, columns=onehot_columns)\n",
    "        df = df.drop(columns=onehot_features)\n",
    "        df = df.join(onehot_data)\n",
    "    # MEAN ENCODING\n",
    "    if mean_features:\n",
    "        for col in mean_features:\n",
    "            df[col] = df[col].map(mean_encoder[col])\n",
    "            df[col] = df[col].fillna(mean_encoder['unk'])\n",
    "    \n",
    "    # delete features\n",
    "    df = df.drop(columns=delete_columns)\n",
    "    if not test:\n",
    "        df = df.drop(columns=['Salario mensual (en tu moneda local)'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_444\\2677888223.py:88: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Años de experiencia'] = pd.to_numeric(df['Años de experiencia'].str.split(',').str[0].str.replace('\\D+', ''))\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_444\\2677888223.py:94: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Años en el puesto actual'] = pd.to_numeric(df['Años en el puesto actual'].str.split(',').str[0].str.replace('\\D+', ''))\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_444\\2677888223.py:127: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['Tengo'] = pd.to_numeric(df['Tengo'].str.replace('\\D+', ''))\n"
     ]
    }
   ],
   "source": [
    "train = clean_pipeline(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45227, 59)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = clean_pipeline(test, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5368, 58)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mljar",
   "language": "python",
   "name": "mljar"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
